{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from cnn_finetune import make_model\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "    # pause a bit so that plots are updated\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_url_to_local_path(url):\n",
    "    '''\n",
    "    gets the location of the image in the shared directory so we don't have to redownload\n",
    "    '''\n",
    "    return '/home/jovyan/course/ladi/'+'/'.join(url.split('/')[3:])\n",
    "\n",
    "def labeltonumpy_i(label):\n",
    "    int_list = [int(x) for x in (label[1:-1].split(' '))]\n",
    "    return np.array(int_list)\n",
    "\n",
    "class MLCNN_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, label_csv, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with metadata.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.final_metadata = pd.read_csv(csv_file)\n",
    "        \n",
    "        # get the path in the shared directory\n",
    "        self.final_metadata['local_path'] = self.final_metadata['url'].apply(convert_url_to_local_path)\n",
    "        \n",
    "        self.final_label = pd.read_csv(label_csv)\n",
    "        \n",
    "        self.final_label['label'] = self.final_label['label'].apply(labeltonumpy_i)\n",
    "        \n",
    "        self.final_data = pd.merge(self.final_metadata, \n",
    "                                        self.final_label,\n",
    "                                       on=\"s3_path\").drop(['Unnamed: 0_x','Unnamed: 0_y'],axis = 1)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.final_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        ## Load images from shared directory. There is no need to download images to local machine. ##\n",
    "        local_path = self.final_metadata.iloc[idx]['local_path']\n",
    "        url = self.final_metadata.iloc[idx]['url']\n",
    "        try:\n",
    "            image = Image.fromarray(io.imread(local_path))\n",
    "            img_name = local_path\n",
    "        except:\n",
    "            image = Image.fromarray(io.imread(url))\n",
    "            img_name = url\n",
    "        uuid = self.final_data.iloc[idx, 1]\n",
    "        timestamp = self.final_data.iloc[idx, 2]\n",
    "        gps_lat = self.final_data.iloc[idx, 3]\n",
    "        gps_lon = self.final_data.iloc[idx, 4]\n",
    "        gps_alt = self.final_data.iloc[idx, 5]\n",
    "        file_size = self.final_data.iloc[idx, 6]\n",
    "        width = self.final_data.iloc[idx, 7]\n",
    "        height = self.final_data.iloc[idx, 8]\n",
    "        label = self.final_data.iloc[idx, -1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sample = {'image': image, 'label': label}#, 'uuid': uuid, 'timestamp': timestamp, 'gps_lat': gps_lat, 'gps_lon': gps_lon, 'gps_alt': gps_alt, 'orig_file_size': file_size, 'orig_width': width, 'orig_height': height}\n",
    "\n",
    "        return sample\n",
    "\n",
    "final_dataset = MLCNN_Dataset(csv_file = 'final_metadata.csv', label_csv = 'changedLabels.csv')\n",
    "\n",
    "scale = transforms.Resize(768)\n",
    "crop = transforms.RandomCrop(512)\n",
    "rotate = transforms.RandomRotation(25)\n",
    "#flip_demo = transforms.RandomHorizontalFlip(1) # flip with 100% chance just to demo\n",
    "flip = transforms.RandomHorizontalFlip(p=0.5)\n",
    "composed = transforms.Compose([scale,\n",
    "                               crop,\n",
    "                               rotate,\n",
    "                               flip,\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "Transformed_dataset = MLCNN_Dataset(csv_file = 'final_metadata.csv', label_csv = 'changedLabels.csv',\n",
    "                                          transform = transforms.Compose([scale, crop, rotate, flip, transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gps_lat</th>\n",
       "      <th>gps_lon</th>\n",
       "      <th>gps_alt</th>\n",
       "      <th>file_size</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>s3_path</th>\n",
       "      <th>url</th>\n",
       "      <th>local_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f3a9a1d1324b747b16d5ddd88b1e582d4430d952</td>\n",
       "      <td>2015-10-08 12:33:11</td>\n",
       "      <td>33.642213</td>\n",
       "      <td>-79.835887</td>\n",
       "      <td>292.0</td>\n",
       "      <td>6388659.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0512_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489efbec368d78a08e08aef15f21409745231328</td>\n",
       "      <td>2015-10-08 12:33:32</td>\n",
       "      <td>33.647137</td>\n",
       "      <td>-79.829637</td>\n",
       "      <td>306.0</td>\n",
       "      <td>6283783.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0516_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38b2cdf28c9f06cf3adac2f1dd0c50332e3a3ab9</td>\n",
       "      <td>2015-10-08 12:33:43</td>\n",
       "      <td>33.650238</td>\n",
       "      <td>-79.834105</td>\n",
       "      <td>301.0</td>\n",
       "      <td>6990298.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0521_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405c090c177e5f22cabc7ff4124dbbdd66bd3413</td>\n",
       "      <td>2015-10-08 12:35:10</td>\n",
       "      <td>33.611918</td>\n",
       "      <td>-79.836295</td>\n",
       "      <td>331.0</td>\n",
       "      <td>6525512.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0529_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d3f72158df1bea3fbe99c1b9c0df2c1bc1ab1a94</td>\n",
       "      <td>2015-10-09 11:01:41</td>\n",
       "      <td>33.476848</td>\n",
       "      <td>-79.556262</td>\n",
       "      <td>388.0</td>\n",
       "      <td>6244449.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20211/DSC_1028_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       uuid            timestamp    gps_lat  \\\n",
       "0  f3a9a1d1324b747b16d5ddd88b1e582d4430d952  2015-10-08 12:33:11  33.642213   \n",
       "1  489efbec368d78a08e08aef15f21409745231328  2015-10-08 12:33:32  33.647137   \n",
       "2  38b2cdf28c9f06cf3adac2f1dd0c50332e3a3ab9  2015-10-08 12:33:43  33.650238   \n",
       "3  405c090c177e5f22cabc7ff4124dbbdd66bd3413  2015-10-08 12:35:10  33.611918   \n",
       "4  d3f72158df1bea3fbe99c1b9c0df2c1bc1ab1a94  2015-10-09 11:01:41  33.476848   \n",
       "\n",
       "     gps_lon  gps_alt  file_size   width  height  \\\n",
       "0 -79.835887    292.0  6388659.0  6000.0  4000.0   \n",
       "1 -79.829637    306.0  6283783.0  6000.0  4000.0   \n",
       "2 -79.834105    301.0  6990298.0  6000.0  4000.0   \n",
       "3 -79.836295    331.0  6525512.0  6000.0  4000.0   \n",
       "4 -79.556262    388.0  6244449.0  6000.0  4000.0   \n",
       "\n",
       "                                             s3_path  \\\n",
       "0  s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0512_...   \n",
       "1  s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0516_...   \n",
       "2  s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0521_...   \n",
       "3  s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0529_...   \n",
       "4  s3://ladi/Images/FEMA_CAP/1013/20211/DSC_1028_...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "1  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "2  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "3  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "4  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "\n",
       "                                          local_path  \\\n",
       "0  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "1  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "2  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "3  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "4  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "\n",
       "                                           label  \n",
       "0  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transformed_dataset.final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "test_split_ratio = .3\n",
    "shuffle_dataset = True\n",
    "random_seed= 76\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(Transformed_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split_ratio * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Transformed_dataset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler, num_workers = 2)\n",
    "test_loader = torch.utils.data.DataLoader(Transformed_dataset, batch_size=4,\n",
    "                                                sampler=test_sampler, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Medium Code\n",
    "# files = glob('img_align_celeba/*.jpg')\n",
    "# shuffle = np.random.permutation(len(files))\n",
    "# for i in ['train', 'valid']:\n",
    "#     os.mkdir(os.path.join('/tmp/', i))\n",
    "    \n",
    "# valid_dict = {}\n",
    "# valid_file_names = []\n",
    "# for i in tqdm(shuffle[:60780]):\n",
    "#     file_name = files[i].split('/')[-1]\n",
    "#     labels = np.array(label_df[label_df.index==file_name])\n",
    "#     valid_dict[file_name] = labels\n",
    "#     valid_file_names.append(file_name)\n",
    "#     os.rename(files[i], os.path.join('/tmp/', '/tmp/valid', file_name))\n",
    "# valid_df.index = valid_file_names\n",
    "# valid_df.columns = ['labels']\n",
    "\n",
    "## uncomment the below given line to check the head of the dataframe\n",
    "# valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassifier, self).__init__()\n",
    "        self.ConvLayer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3), # 3, 256, 256\n",
    "            nn.MaxPool2d(2), # op: 16, 127, 127\n",
    "            nn.ReLU(), # op: 64, 127, 127\n",
    "        )\n",
    "        self.ConvLayer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3), # 64, 127, 127   \n",
    "            nn.MaxPool2d(2), #op: 128, 63, 63\n",
    "            nn.ReLU() # op: 128, 63, 63\n",
    "        )\n",
    "        self.ConvLayer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3), # 128, 63, 63\n",
    "            nn.MaxPool2d(2), #op: 256, 30, 30\n",
    "            nn.ReLU() #op: 256, 30, 30\n",
    "        )\n",
    "        self.ConvLayer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3), # 256, 30, 30\n",
    "            nn.MaxPool2d(2), #op: 512, 14, 14\n",
    "            nn.ReLU(), #op: 512, 14, 14\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.Linear1 = nn.Linear(460800, 1024)\n",
    "        self.Linear2 = nn.Linear(1024, 256)\n",
    "        self.Linear3 = nn.Linear(256, 15)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ConvLayer1(x)\n",
    "        x = self.ConvLayer2(x)\n",
    "        x = self.ConvLayer3(x)\n",
    "        x = self.ConvLayer4(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.Linear1(x)\n",
    "        x = self.Linear2(x)\n",
    "        x = self.Linear3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiClassifier().cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=100, momentum = 0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_acc(original, predicted):\n",
    "    return torch.round(predicted).eq(original).sum().numpy()/len(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our code\n",
    "torch.autograd.set_detect_anomaly = False\n",
    "def fit_model(epochs, model, dataloader, phase = 'training', volatile = False):\n",
    "    \n",
    "    pprint(\"Epoch: {}\".format(epochs))\n",
    "    \n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "        \n",
    "    if phase == 'validataion':\n",
    "        model.eval()\n",
    "        volatile = True\n",
    "        \n",
    "    running_loss = []\n",
    "    running_acc = []\n",
    "    b = 0\n",
    "    #print('a')\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        #print('b')\n",
    "\n",
    "        inputs, target = data['image'].cuda(), data['label'].float().cuda()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "            #print('c')\n",
    "        ops = model(inputs)\n",
    "        \n",
    "        acc_ = []\n",
    "        for j, d in enumerate(ops, 0):\n",
    "            #print('d')\n",
    "            acc = pred_acc(torch.Tensor.cpu(target[j]), torch.Tensor.cpu(d))\n",
    "            acc_.append(acc)\n",
    "\n",
    "        loss = criterion(ops, target)\n",
    "                \n",
    "        running_loss.append(loss.item())\n",
    "        running_acc.append(np.asarray(acc_).mean())\n",
    "        b += 1\n",
    "        #print('e')\n",
    "        if phase == 'training':\n",
    "            \n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            #print('f')\n",
    "        print(f'[epoch {epochs}, batch {i +1} ] average loss: {loss.item()}')\n",
    "            \n",
    "    total_batch_loss = np.asarray(running_loss).mean()\n",
    "    total_batch_acc = np.asarray(running_acc).mean()\n",
    "    #print('g')\n",
    "\n",
    "    pprint(\"{} loss is {} \".format(phase,total_batch_loss))\n",
    "    pprint(\"{} accuracy is {} \".format(phase, total_batch_acc))\n",
    "    \n",
    "    return total_batch_loss, total_batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 28 21:05:55 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   54C    P0    29W /  70W |   2481MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "#Make sure GPU doesn't forget to be a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Epoch: 1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:06,  6.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 1 ] average loss: 0.6960441470146179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:06,  4.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 2 ] average loss: 1.842068076133728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:10,  4.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 3 ] average loss: 4.1446533203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:11,  3.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 4 ] average loss: 7.368271827697754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [00:15,  3.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 5 ] average loss: 11.973443031311035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:15,  2.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 6 ] average loss: 12.4339599609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [00:20,  3.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 7 ] average loss: 14.27602767944336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:21,  2.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 8 ] average loss: 15.887835502624512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9it [00:24,  2.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 9 ] average loss: 12.664217948913574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:24,  2.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 10 ] average loss: 7.828789234161377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:28,  2.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 11 ] average loss: 5.295945644378662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12it [00:28,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 12 ] average loss: 4.374911308288574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "13it [00:32,  2.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 13 ] average loss: 5.065687656402588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "14it [00:33,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 14 ] average loss: 4.835428714752197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:38,  2.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 15 ] average loss: 2.7631022930145264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "16it [00:38,  2.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 16 ] average loss: 2.532843828201294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:41,  2.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 17 ] average loss: 2.3025851249694824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "18it [00:42,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 18 ] average loss: 2.07232666015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "19it [00:46,  2.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 19 ] average loss: 2.993360757827759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "20it [00:46,  1.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 20 ] average loss: 3.223618984222412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [00:50,  2.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 21 ] average loss: 2.7631020545959473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "22it [00:51,  1.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 22 ] average loss: 2.993360757827759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "23it [00:55,  2.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 23 ] average loss: 2.532843828201294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "24it [00:55,  1.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 24 ] average loss: 3.4538774490356445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [01:00,  2.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 25 ] average loss: 2.532843589782715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "26it [01:00,  1.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 26 ] average loss: 3.684136152267456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "27it [01:05,  2.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 27 ] average loss: 3.223618984222412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "28it [01:05,  2.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 28 ] average loss: 2.993360757827759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "29it [01:09,  2.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 29 ] average loss: 2.7631020545959473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30it [01:10,  2.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 30 ] average loss: 2.532843589782715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [01:14,  2.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 31 ] average loss: 2.3025851249694824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "32it [01:14,  1.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 32 ] average loss: 3.223618984222412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "33it [01:20,  3.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 33 ] average loss: 2.7631022930145264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "34it [01:20,  2.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 34 ] average loss: 2.7631022930145264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "35it [01:25,  2.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 35 ] average loss: 3.223619222640991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "36it [01:25,  2.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 36 ] average loss: 2.072326421737671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "37it [01:29,  2.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 37 ] average loss: 3.223618984222412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "38it [01:30,  2.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch 38 ] average loss: 2.993360996246338\n"
     ]
    }
   ],
   "source": [
    "#This better work\n",
    "\n",
    "# --> Ctrl + Enter at your own risk <--\n",
    "\n",
    "trn_losses = []; trn_acc = []\n",
    "val_losses = []; val_acc = []\n",
    "for i in tqdm(range(1, 20)):\n",
    "    trn_l, trn_a = fit_model(i, model, train_loader)\n",
    "    val_l, val_a = fit_model(i, model, test_loader, phase = 'validation')\n",
    "    trn_losses.append(trn_l); trn_acc.append(trn_a)\n",
    "    val_losses.append(val_l); val_acc.append(val_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
