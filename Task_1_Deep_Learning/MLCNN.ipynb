{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from cnn_finetune import make_model\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "    # pause a bit so that plots are updated\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_url_to_local_path(url):\n",
    "    '''\n",
    "    gets the location of the image in the shared directory so we don't have to redownload\n",
    "    '''\n",
    "    return '/home/jovyan/course/ladi/'+'/'.join(url.split('/')[3:])\n",
    "\n",
    "def labeltonumpy_i(label):\n",
    "    int_list = [int(x) for x in (label[1:-1].split(' '))]\n",
    "    return np.array(int_list)\n",
    "\n",
    "class MLCNN_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, label_csv, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with metadata.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.final_metadata = pd.read_csv(csv_file)\n",
    "        \n",
    "        # get the path in the shared directory\n",
    "        self.final_metadata['local_path'] = self.final_metadata['url'].apply(convert_url_to_local_path)\n",
    "        \n",
    "        self.final_label = pd.read_csv(label_csv)\n",
    "        \n",
    "        self.final_label['label'] = self.final_label['label'].apply(labeltonumpy_i)\n",
    "        \n",
    "        self.final_data = pd.merge(self.final_metadata, \n",
    "                                        self.final_label,\n",
    "                                       on=\"s3_path\").drop(['Unnamed: 0_x','Unnamed: 0_y'],axis = 1)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.final_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        ## Load images from shared directory. There is no need to download images to local machine. ##\n",
    "        local_path = self.final_metadata.iloc[idx]['local_path']\n",
    "        url = self.final_metadata.iloc[idx]['url']\n",
    "        try:\n",
    "            image = Image.fromarray(io.imread(local_path))\n",
    "            img_name = local_path\n",
    "        except:\n",
    "            image = Image.fromarray(io.imread(url))\n",
    "            img_name = url\n",
    "        uuid = self.final_data.iloc[idx, 1]\n",
    "        timestamp = self.final_data.iloc[idx, 2]\n",
    "        gps_lat = self.final_data.iloc[idx, 3]\n",
    "        gps_lon = self.final_data.iloc[idx, 4]\n",
    "        gps_alt = self.final_data.iloc[idx, 5]\n",
    "        file_size = self.final_data.iloc[idx, 6]\n",
    "        width = self.final_data.iloc[idx, 7]\n",
    "        height = self.final_data.iloc[idx, 8]\n",
    "        label = self.final_data.iloc[idx, -1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sample = {'image': image, 'label': label}#, 'uuid': uuid, 'timestamp': timestamp, 'gps_lat': gps_lat, 'gps_lon': gps_lon, 'gps_alt': gps_alt, 'orig_file_size': file_size, 'orig_width': width, 'orig_height': height}\n",
    "\n",
    "        return sample\n",
    "\n",
    "final_dataset = MLCNN_Dataset(csv_file = 'final_metadata.csv', label_csv = 'changedLabels.csv')\n",
    "\n",
    "scale = transforms.Resize(768)\n",
    "crop = transforms.RandomCrop(512)\n",
    "rotate = transforms.RandomRotation(25)\n",
    "#flip_demo = transforms.RandomHorizontalFlip(1) # flip with 100% chance just to demo\n",
    "flip = transforms.RandomHorizontalFlip(p=0.5)\n",
    "composed = transforms.Compose([scale,\n",
    "                               crop,\n",
    "                               rotate,\n",
    "                               flip,\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "Transformed_dataset = MLCNN_Dataset(csv_file = 'final_metadata.csv', label_csv = 'changedLabels.csv',\n",
    "                                          transform = transforms.Compose([scale, crop, rotate, flip, transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gps_lat</th>\n",
       "      <th>gps_lon</th>\n",
       "      <th>gps_alt</th>\n",
       "      <th>file_size</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>s3_path</th>\n",
       "      <th>url</th>\n",
       "      <th>local_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f3a9a1d1324b747b16d5ddd88b1e582d4430d952</td>\n",
       "      <td>2015-10-08 12:33:11</td>\n",
       "      <td>33.642213</td>\n",
       "      <td>-79.835887</td>\n",
       "      <td>292.0</td>\n",
       "      <td>6388659.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0512_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489efbec368d78a08e08aef15f21409745231328</td>\n",
       "      <td>2015-10-08 12:33:32</td>\n",
       "      <td>33.647137</td>\n",
       "      <td>-79.829637</td>\n",
       "      <td>306.0</td>\n",
       "      <td>6283783.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0516_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38b2cdf28c9f06cf3adac2f1dd0c50332e3a3ab9</td>\n",
       "      <td>2015-10-08 12:33:43</td>\n",
       "      <td>33.650238</td>\n",
       "      <td>-79.834105</td>\n",
       "      <td>301.0</td>\n",
       "      <td>6990298.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0521_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405c090c177e5f22cabc7ff4124dbbdd66bd3413</td>\n",
       "      <td>2015-10-08 12:35:10</td>\n",
       "      <td>33.611918</td>\n",
       "      <td>-79.836295</td>\n",
       "      <td>331.0</td>\n",
       "      <td>6525512.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0529_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d3f72158df1bea3fbe99c1b9c0df2c1bc1ab1a94</td>\n",
       "      <td>2015-10-09 11:01:41</td>\n",
       "      <td>33.476848</td>\n",
       "      <td>-79.556262</td>\n",
       "      <td>388.0</td>\n",
       "      <td>6244449.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>s3://ladi/Images/FEMA_CAP/1013/20211/DSC_1028_...</td>\n",
       "      <td>https://ladi.s3-us-west-2.amazonaws.com/Images...</td>\n",
       "      <td>/home/jovyan/course/ladi/Images/FEMA_CAP/1013/...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       uuid            timestamp    gps_lat  \\\n",
       "0  f3a9a1d1324b747b16d5ddd88b1e582d4430d952  2015-10-08 12:33:11  33.642213   \n",
       "1  489efbec368d78a08e08aef15f21409745231328  2015-10-08 12:33:32  33.647137   \n",
       "2  38b2cdf28c9f06cf3adac2f1dd0c50332e3a3ab9  2015-10-08 12:33:43  33.650238   \n",
       "3  405c090c177e5f22cabc7ff4124dbbdd66bd3413  2015-10-08 12:35:10  33.611918   \n",
       "4  d3f72158df1bea3fbe99c1b9c0df2c1bc1ab1a94  2015-10-09 11:01:41  33.476848   \n",
       "\n",
       "     gps_lon  gps_alt  file_size   width  height  \\\n",
       "0 -79.835887    292.0  6388659.0  6000.0  4000.0   \n",
       "1 -79.829637    306.0  6283783.0  6000.0  4000.0   \n",
       "2 -79.834105    301.0  6990298.0  6000.0  4000.0   \n",
       "3 -79.836295    331.0  6525512.0  6000.0  4000.0   \n",
       "4 -79.556262    388.0  6244449.0  6000.0  4000.0   \n",
       "\n",
       "                                             s3_path  \\\n",
       "0  s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0512_...   \n",
       "1  s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0516_...   \n",
       "2  s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0521_...   \n",
       "3  s3://ladi/Images/FEMA_CAP/1013/20195/DSC_0529_...   \n",
       "4  s3://ladi/Images/FEMA_CAP/1013/20211/DSC_1028_...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "1  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "2  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "3  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "4  https://ladi.s3-us-west-2.amazonaws.com/Images...   \n",
       "\n",
       "                                          local_path  \\\n",
       "0  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "1  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "2  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "3  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "4  /home/jovyan/course/ladi/Images/FEMA_CAP/1013/...   \n",
       "\n",
       "                                           label  \n",
       "0  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transformed_dataset.final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "test_split_ratio = .3\n",
    "shuffle_dataset = True\n",
    "random_seed= 76\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(Transformed_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split_ratio * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Transformed_dataset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler, num_workers = 2)\n",
    "test_loader = torch.utils.data.DataLoader(Transformed_dataset, batch_size=16,\n",
    "                                                sampler=test_sampler, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Medium Code\n",
    "# files = glob('img_align_celeba/*.jpg')\n",
    "# shuffle = np.random.permutation(len(files))\n",
    "# for i in ['train', 'valid']:\n",
    "#     os.mkdir(os.path.join('/tmp/', i))\n",
    "    \n",
    "# valid_dict = {}\n",
    "# valid_file_names = []\n",
    "# for i in tqdm(shuffle[:60780]):\n",
    "#     file_name = files[i].split('/')[-1]\n",
    "#     labels = np.array(label_df[label_df.index==file_name])\n",
    "#     valid_dict[file_name] = labels\n",
    "#     valid_file_names.append(file_name)\n",
    "#     os.rename(files[i], os.path.join('/tmp/', '/tmp/valid', file_name))\n",
    "# valid_df.index = valid_file_names\n",
    "# valid_df.columns = ['labels']\n",
    "\n",
    "## uncomment the below given line to check the head of the dataframe\n",
    "# valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassifier, self).__init__()\n",
    "        self.ConvLayer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3), # 3, 256, 256\n",
    "            nn.MaxPool2d(2), # op: 16, 127, 127\n",
    "            nn.ReLU(), # op: 64, 127, 127\n",
    "        )\n",
    "        self.ConvLayer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3), # 64, 127, 127   \n",
    "            nn.MaxPool2d(2), #op: 128, 63, 63\n",
    "            nn.ReLU() # op: 128, 63, 63\n",
    "        )\n",
    "        self.ConvLayer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3), # 128, 63, 63\n",
    "            nn.MaxPool2d(2), #op: 256, 30, 30\n",
    "            nn.ReLU() #op: 256, 30, 30\n",
    "        )\n",
    "        self.ConvLayer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3), # 256, 30, 30\n",
    "            nn.MaxPool2d(2), #op: 512, 14, 14\n",
    "            nn.ReLU(), #op: 512, 14, 14\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.Linear1 = nn.Linear(460800, 1024)\n",
    "        self.Linear2 = nn.Linear(1024, 256)\n",
    "        self.Linear3 = nn.Linear(256, 15)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ConvLayer1(x)\n",
    "        x = self.ConvLayer2(x)\n",
    "        x = self.ConvLayer3(x)\n",
    "        x = self.ConvLayer4(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.Linear1(x)\n",
    "        x = self.Linear2(x)\n",
    "        x = self.Linear3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f0698faaf21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = MultiClassifier().cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model = make_model('alexnet', num_classes=15, pretrained=True, input_size = (768,768)).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet18'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "model = MultiClassifier().cuda()\n",
    "#model = make_model('alexnet', num_classes=15, pretrained=True, input_size = (768,768)).cuda()\n",
    "#model = make_model('resnet18', num_classes=2, pretrained=True).cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_acc(original, predicted):\n",
    "    return torch.round(predicted).eq(original).sum().numpy()/len(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our code\n",
    "torch.autograd.set_detect_anomaly = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "def fit_model(epochs, model, dataloader, phase = 'training', volatile = False):\n",
    "    \n",
    "    pprint(\"Epoch: {}\".format(epochs))\n",
    "    \n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "        \n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile = True\n",
    "        \n",
    "    running_loss = []\n",
    "    running_acc = []\n",
    "    b = 0\n",
    "    #print('a')\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "        #print('b')\n",
    "\n",
    "        inputs, target = data['image'].cuda(), data['label'].float().cuda()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "            #print('c')\n",
    "        ops = model(inputs)\n",
    "        \n",
    "        acc_ = []\n",
    "        for j, d in enumerate(ops, 0):\n",
    "            #print('d')\n",
    "            acc = pred_acc(torch.Tensor.cpu(target[j]), torch.Tensor.cpu(d))\n",
    "            acc_.append(acc)\n",
    "\n",
    "        loss = criterion(ops, target)\n",
    "                \n",
    "        running_loss.append(loss.item())\n",
    "        running_acc.append(np.asarray(acc_).mean())\n",
    "        b += 1\n",
    "        #print('e')\n",
    "        if phase == 'training':\n",
    "            \n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            #print('f')\n",
    "        print(f'[epoch {epochs}, batch {i +1} ] average loss: {loss.item()}')\n",
    "            \n",
    "    total_batch_loss = np.asarray(running_loss).mean()\n",
    "    total_batch_acc = np.asarray(running_acc).mean()\n",
    "    #print('g')\n",
    "\n",
    "    pprint(\"{} loss is {} \".format(phase,total_batch_loss))\n",
    "    pprint(\"{} accuracy is {} \".format(phase, total_batch_acc))\n",
    "    \n",
    "    return total_batch_loss, total_batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 28 22:23:16 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   62C    P0    31W /  70W |  13763MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "#Make sure GPU doesn't forget to be a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Epoch: 1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:11, ?it/s]\u001b[A\n",
      "  0%|          | 0/19 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "reduce failed to synchronize: cudaErrorAssert: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-395943f54063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrn_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mval_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrn_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtrn_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c840ea6d00c9>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(epochs, model, dataloader, phase, volatile)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0macc_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2077\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "#This better work\n",
    "\n",
    "# --> Ctrl + Enter at your own risk <--\n",
    "\n",
    "trn_losses = []; trn_acc = []\n",
    "val_losses = []; val_acc = []\n",
    "for i in tqdm(range(1, 20)):\n",
    "    trn_l, trn_a = fit_model(i, model, train_loader)\n",
    "    val_l, val_a = fit_model(i, model, test_loader, phase = 'validation')\n",
    "    trn_losses.append(trn_l); trn_acc.append(trn_a)\n",
    "    val_losses.append(val_l); val_acc.append(val_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
